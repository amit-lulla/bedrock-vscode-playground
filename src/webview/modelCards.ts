/* eslint-disable @typescript-eslint/naming-convention */
export const titanTextExpressModelCard = `
<p> AI and ML have been a focus for Amazon for over 20 years, and many of the capabilities customers use with Amazon are driven by ML. Amazon Titan models are built by leveraging Amazon’s decades of experience to make ML accessible to anyone who wants to use it. </p>

<p> Amazon Titan Foundation Models are pre-trained on large datasets, making them powerful, general-purpose models. Use them as is, or customize them by fine tuning the models with your own data for a particular task without annotating large volumes of data.</p>

<p> Titan Text Generation 1 (G1) - Express is a generative large language model (LLM) for tasks such as summarization, text generation (for example, creating a blog post), classification, open-ended Q&A, and information extraction.

    <ul>
        <li> Version: 1 (preview)</li>
        <li> Max tokens: 8k </li>
        <li> Languages: English </li>
        <li> Supported formats: Open ended text generation, brainstorming, summarization, code generation, table creation, data formatting, paraphrasing, chain of thought, rewrite, extraction, Q&A, chat </li>
        <li> Model attributes: Text generation, Code generation, Instruction following </li>
    </ul>
</p>
`;

export const titanTextLiteModelCard = `
<p> AI and ML have been a focus for Amazon for over 20 years, and many of the capabilities customers use with Amazon are driven by ML. Amazon Titan models are built by leveraging Amazon’s decades of experience to make ML accessible to anyone who wants to use it. </p>

<p> Amazon Titan Foundation Models are pre-trained on large datasets, making them powerful, general-purpose models. Use them as is, or customize them by fine tuning the models with your own data for a particular task without annotating large volumes of data.</p>

<p> Titan Text Generation 1 (G1) - Lite is a generative large language model (LLM) for tasks such as summarization, text generation (for example, creating a blog post), classification, open-ended Q&A, and information extraction.

    <ul>
        <li> Version: 1 (preview)</li>
        <li> Max tokens: 4k </li>
        <li> Languages: English </li>
        <li> Supported formats: Open ended text generation, brainstorming, summarization, code generation, table creation, data formatting, paraphrasing, chain of thought, rewrite, extraction, Q&A, chat </li>
        <li> Model attributes: Text generation, Code generation, Instruction following </li>
    </ul>
</p>
`;

export const claude_2_ModelCard = `
<p> Anthropic's most powerful model, which excels at a wide range of tasks from sophisticated dialogue and creative content generation to detailed instruction following.
    <ul>
        <li> Version: 2</li>
        <li> Max tokens: 100k </li>
        <li> Languages: Multilingual </li>
        <li> Supported use cases: Question answering, information extraction, removing PII, content generation, multiple choice classification, Roleplay, comparing text, summarization, document Q&A with citation </li>
        <li> Text generation, Conversational </li>
    </ul>
</p>
`;

export const claude_2_1_ModelCard = `
<p> An update to Claude 2 that features double the context window, plus improvements across reliability, hallucination rates, and evidence-based accuracy in long document and RAG contexts.
    <ul>
        <li> Version: 2.1</li>
        <li> Max tokens: 200k </li>
        <li> Languages: Multilingual </li>
        <li> Supported use cases: Question answering, information extraction, removing PII, content generation, multiple choice classification, Roleplay, comparing text, summarization, document Q&A with citation </li>
        <li> Text generation, Conversation, Complex reasoning & analysis </li>
    </ul>
</p>
`;

export const claudeInstantModelCard = `
<p> A faster and cheaper yet still very capable model, which can handle a range of tasks including casual dialogue, text analysis, summarization, and document question-answering.
    <ul>
        <li> Version: 1.2</li>
        <li> Max tokens: 100k </li>
        <li> Languages: Multilingual </li>
        <li> Supported use cases: Question answering, information extraction, removing PII, content generation, multiple choice classification, Roleplay, comparing text, summarization, document Q&A with citation </li>
        <li> Text generation, Conversational </li>
    </ul>
</p>
`;

export const commandModelCard = `

<p> Command is a text generation model for business use cases. Command is trained on data that supports reliable business applications, like text generation, summarization, copywriting, dialogue, extraction, and question answering.
    <ul>
        <li> Version: 14.7</li>
        <li> Max tokens: 4096 </li>
        <li> Languages: English </li>
        <li> Supported use cases: Summarization, copywriting, dialogue, extraction, and question answering. </li>
        <li> Model attributes: Text generation, Instruction following </li>
    </ul>
</p>
`;

export const commandLightModelCard = `

<p> Cohere's Command-Light is a generative model that responds well with instruction-like prompts. This model provides customers with an unbeatable balance of quality, cost-effectiveness, and low-latency inference.
    <ul>
        <li> Version: 14.7</li>
        <li> Max tokens: 4000 </li>
        <li> Languages: English </li>
        <li> Supported use cases: Summarization, copywriting, dialogue, extraction, and question answering. </li>
        <li> Model attributes: Text generation, Instruction following </li>
    </ul>
</p>
`;

export const jurassicUltraModelCard = `
<p> Jurassic-2 Ultra is AI21’s most powerful model offering exceptional quality. Apply Jurassic-2 Ultra to complex tasks that require advanced text generation and comprehension. Popular use cases include question answering, summarization, long-form copy generation, advanced information extraction, and more.
    <ul>
        <li> Version: 1</li>
        <li> Max tokens: 8191 </li>
        <li> Languages: English, Spanish, French, German, Portuguese, Italian, Dutch </li>
        <li> Supported use cases: Open book question answering, summarization, draft generation, information extraction, ideation </li>
        <li> Model attributes: Text, Classification, Insert/edit </li>
    </ul>
</p>
`;

export const jurassicMidModelCard = `
<p> Jurassic-2 Mid is AI21’s mid-sized model, carefully designed to strike the right balance between exceptional quality and affordability. Jurassic-2 Mid can be applied to any language comprehension or generation task including question answering, summarization, long-form copy generation, advanced information extraction and many others.
    <ul>
        <li> Version: 1</li>
        <li> Max tokens: 8191 </li>
        <li> Languages: English, Spanish, French, German, Portuguese, Italian, Dutch </li>
        <li> Supported use cases: Open book question answering, summarization, draft generation, information extraction, ideation </li>
        <li> Model attributes: Text, Classification, Insert/edit, Math </li>
    </ul>
</p>
`;

export const llama_2_ModelCard = `
<p> A dialogue use case optimized variant of Llama 2 models. Llama 2 is an auto-regressive language model that uses an optimized transformer architecture. Llama 2 is intended for commercial and research use in English.
    <ul>
        <li> Version: 1</li>
        <li> Max tokens: 4096 </li>
        <li> Languages: English</li>
        <li> Supported use cases: Llama 2 is intended for commercial and research use in English. Fine-tuned chat models are intended for chat based applications. </li>
        <li> Use in any manner that violates applicable laws or regulations (including trade compliance laws). Use in any other way that is prohibited by the Acceptable Use Policy and Llama 2 Community License.</li>
        <li> Model attributes: Text generation, Chat optimized, Conversational </li>
    </ul>
</p>
`;